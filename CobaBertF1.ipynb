{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "df = pd.read_csv('mobil_listrik.csv')\n",
    "df.head()\n",
    "# drop nan values\n",
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentimen\n",
       "negatif    868\n",
       "positif    504\n",
       "netral     142\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['sentimen'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at indobenchmark/indobert-base-p1 and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98a12ac56c934326af1aec977e132f36",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/228 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.982, 'grad_norm': 5.027266025543213, 'learning_rate': 1.0000000000000002e-06, 'epoch': 0.13}\n",
      "{'loss': 0.9437, 'grad_norm': 7.30647611618042, 'learning_rate': 2.0000000000000003e-06, 'epoch': 0.26}\n",
      "{'loss': 0.9311, 'grad_norm': 4.135098457336426, 'learning_rate': 3e-06, 'epoch': 0.39}\n",
      "{'loss': 0.906, 'grad_norm': 9.081064224243164, 'learning_rate': 4.000000000000001e-06, 'epoch': 0.53}\n",
      "{'loss': 0.8562, 'grad_norm': 3.2632529735565186, 'learning_rate': 5e-06, 'epoch': 0.66}\n",
      "{'loss': 0.9443, 'grad_norm': 4.320446491241455, 'learning_rate': 6e-06, 'epoch': 0.79}\n",
      "{'loss': 0.8797, 'grad_norm': 5.549627780914307, 'learning_rate': 7.000000000000001e-06, 'epoch': 0.92}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aade19848344f46924257d702732562",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.9031966328620911, 'eval_f1': 0.38939801471348745, 'eval_runtime': 66.3564, 'eval_samples_per_second': 4.566, 'eval_steps_per_second': 0.286, 'epoch': 1.0}\n",
      "{'loss': 0.8402, 'grad_norm': 4.391604423522949, 'learning_rate': 8.000000000000001e-06, 'epoch': 1.05}\n",
      "{'loss': 0.827, 'grad_norm': 8.601346015930176, 'learning_rate': 9e-06, 'epoch': 1.18}\n",
      "{'loss': 0.8386, 'grad_norm': 5.207475662231445, 'learning_rate': 1e-05, 'epoch': 1.32}\n",
      "{'loss': 0.793, 'grad_norm': 3.9837377071380615, 'learning_rate': 1.1000000000000001e-05, 'epoch': 1.45}\n",
      "{'loss': 0.6535, 'grad_norm': 7.207342147827148, 'learning_rate': 1.2e-05, 'epoch': 1.58}\n",
      "{'loss': 0.6934, 'grad_norm': 9.432427406311035, 'learning_rate': 1.3000000000000001e-05, 'epoch': 1.71}\n",
      "{'loss': 0.7952, 'grad_norm': 7.515537261962891, 'learning_rate': 1.4000000000000001e-05, 'epoch': 1.84}\n",
      "{'loss': 0.7782, 'grad_norm': 5.841495990753174, 'learning_rate': 1.5e-05, 'epoch': 1.97}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c5d8a4ffc44440b2c58de0088db6c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7547644972801208, 'eval_f1': 0.6353209861866547, 'eval_runtime': 64.6112, 'eval_samples_per_second': 4.69, 'eval_steps_per_second': 0.294, 'epoch': 2.0}\n",
      "{'loss': 0.6455, 'grad_norm': 5.282618522644043, 'learning_rate': 1.6000000000000003e-05, 'epoch': 2.11}\n",
      "{'loss': 0.6003, 'grad_norm': 12.560521125793457, 'learning_rate': 1.7000000000000003e-05, 'epoch': 2.24}\n",
      "{'loss': 0.5531, 'grad_norm': 14.366499900817871, 'learning_rate': 1.8e-05, 'epoch': 2.37}\n",
      "{'loss': 0.5361, 'grad_norm': 4.900355815887451, 'learning_rate': 1.9e-05, 'epoch': 2.5}\n",
      "{'loss': 0.5499, 'grad_norm': 19.15966033935547, 'learning_rate': 2e-05, 'epoch': 2.63}\n",
      "{'loss': 0.5561, 'grad_norm': 8.900321006774902, 'learning_rate': 2.1e-05, 'epoch': 2.76}\n",
      "{'loss': 0.5761, 'grad_norm': 14.915722846984863, 'learning_rate': 2.2000000000000003e-05, 'epoch': 2.89}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e8e55a86b1f4146b2bbe302551f9640",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.7779859304428101, 'eval_f1': 0.6592220676555992, 'eval_runtime': 64.8293, 'eval_samples_per_second': 4.674, 'eval_steps_per_second': 0.293, 'epoch': 3.0}\n",
      "{'train_runtime': 2771.2, 'train_samples_per_second': 1.311, 'train_steps_per_second': 0.082, 'train_loss': 0.7477182798218309, 'epoch': 3.0}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b72ac45389d04c83951e577a8a66c2db",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation results: {'eval_loss': 0.7779859304428101, 'eval_f1': 0.6592220676555992, 'eval_runtime': 65.1554, 'eval_samples_per_second': 4.65, 'eval_steps_per_second': 0.292, 'epoch': 3.0}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import Dataset, load_metric\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# # Load your dataframe\n",
    "# # Ensure your columns are named correctly\n",
    "# df = pd.DataFrame({\n",
    "#     'text_cleaning': [\"This is a positive text.\", \"This is a negative text.\", \"This is a neutral text.\"],\n",
    "#     'sentimen': ['positif', 'negatif', 'netral']\n",
    "# })\n",
    "\n",
    "# Map the labels to integers\n",
    "label_mapping = {'positif': 0, 'negatif': 1, 'netral': 2}\n",
    "df['labels'] = df['sentimen'].map(label_mapping)\n",
    "\n",
    "# Prepare the tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"indobenchmark/indobert-base-p1\")\n",
    "\n",
    "# Tokenize the texts\n",
    "texts = df['text_cleaning'].tolist()\n",
    "labels = df['labels'].tolist()\n",
    "encodings = tokenizer(texts, truncation=True, padding=True, max_length=128)\n",
    "\n",
    "# Create a Dataset object\n",
    "dataset = Dataset.from_dict({\n",
    "    'input_ids': encodings['input_ids'],\n",
    "    'attention_mask': encodings['attention_mask'],\n",
    "    'labels': labels\n",
    "})\n",
    "\n",
    "# Split the dataset into train and validation sets\n",
    "train_dataset = dataset.shuffle(seed=42).select(range(int(0.8 * len(dataset))))\n",
    "val_dataset = dataset.shuffle(seed=42).select(range(int(0.8 * len(dataset)), len(dataset)))\n",
    "\n",
    "# Load the model\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"indobenchmark/indobert-base-p1\", num_labels=len(label_mapping))\n",
    "\n",
    "# Define the training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    warmup_steps=500,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir='./logs',\n",
    "    logging_steps=10,\n",
    "    evaluation_strategy=\"epoch\"\n",
    ")\n",
    "\n",
    "# Define the F1 metric function with trust_remote_code=True\n",
    "metric = load_metric(\"f1\", trust_remote_code=True)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    # Convert logits to torch Tensor if they are numpy arrays\n",
    "    if isinstance(logits, np.ndarray):\n",
    "        logits = torch.tensor(logits)\n",
    "    # Get predictions by finding the index with the highest value\n",
    "    predictions = torch.argmax(logits, dim=-1)\n",
    "    return metric.compute(predictions=predictions, references=labels, average='weighted')\n",
    "\n",
    "# Initialize the Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    tokenizer=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "trainer.train()\n",
    "\n",
    "# Evaluate the model\n",
    "eval_results = trainer.evaluate()\n",
    "\n",
    "# Print the results\n",
    "print(\"Evaluation results:\", eval_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ./saved_model_f1\n",
      "Tokenizer saved to ./saved_tokenizer_f1\n"
     ]
    }
   ],
   "source": [
    "# Save the model\n",
    "model_path = './saved_model_f1'\n",
    "model.save_pretrained(model_path)\n",
    "\n",
    "# Save the tokenizer\n",
    "tokenizer_path = './saved_tokenizer_f1'\n",
    "tokenizer.save_pretrained(tokenizer_path)\n",
    "\n",
    "print(f\"Model saved to {model_path}\")\n",
    "print(f\"Tokenizer saved to {tokenizer_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "957b76709c6247c78f3cf775e22a8839",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/19 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "     positif       0.66      0.60      0.63       112\n",
      "     negatif       0.70      0.86      0.77       161\n",
      "      netral       0.60      0.10      0.17        30\n",
      "\n",
      "    accuracy                           0.69       303\n",
      "   macro avg       0.65      0.52      0.52       303\n",
      "weighted avg       0.68      0.69      0.66       303\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Get predictions\n",
    "predictions = trainer.predict(val_dataset)\n",
    "\n",
    "# Convert logits to labels\n",
    "logits = predictions.predictions\n",
    "preds = np.argmax(logits, axis=-1)\n",
    "labels = predictions.label_ids\n",
    "\n",
    "# Print classification report\n",
    "report = classification_report(labels, preds, target_names=['positif', 'negatif', 'netral'])\n",
    "print(\"Classification Report:\\n\", report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
